{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11189429,"sourceType":"datasetVersion","datasetId":6985253}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.5.1%2Bcu121.html\n!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.5.1%2Bcu121.html\n!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.5.1%2Bcu121.html\n!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.5.1%2Bcu121.html\n!pip install torch-geometric","metadata":{"trusted":true,"execution":{"iopub.execute_input":"2025-04-02T13:27:06.603949Z","iopub.status.idle":"2025-04-02T13:27:32.347702Z","shell.execute_reply.started":"2025-04-02T13:27:06.603917Z","shell.execute_reply":"2025-04-02T13:27:32.346684Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Looking in links: https://data.pyg.org/whl/torch-2.5.1%2Bcu121.html\nCollecting torch-scatter\n  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/torch_scatter-2.1.2%2Bpt25cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch-scatter\nSuccessfully installed torch-scatter-2.1.2+pt25cu121\nLooking in links: https://data.pyg.org/whl/torch-2.5.1%2Bcu121.html\nCollecting torch-sparse\n  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/torch_sparse-0.6.18%2Bpt25cu121-cp310-cp310-linux_x86_64.whl (5.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\nRequirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch-sparse) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch-sparse) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch-sparse) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch-sparse) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch-sparse) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch-sparse) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.3,>=1.22.4->scipy->torch-sparse) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.3,>=1.22.4->scipy->torch-sparse) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.3,>=1.22.4->scipy->torch-sparse) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.3,>=1.22.4->scipy->torch-sparse) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.3,>=1.22.4->scipy->torch-sparse) (2024.2.0)\nInstalling collected packages: torch-sparse\nSuccessfully installed torch-sparse-0.6.18+pt25cu121\nLooking in links: https://data.pyg.org/whl/torch-2.5.1%2Bcu121.html\nCollecting torch-cluster\n  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/torch_cluster-1.6.3%2Bpt25cu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster) (1.13.1)\nRequirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch-cluster) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch-cluster) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch-cluster) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch-cluster) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch-cluster) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy->torch-cluster) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.3,>=1.22.4->scipy->torch-cluster) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.3,>=1.22.4->scipy->torch-cluster) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.3,>=1.22.4->scipy->torch-cluster) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.3,>=1.22.4->scipy->torch-cluster) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.3,>=1.22.4->scipy->torch-cluster) (2024.2.0)\nInstalling collected packages: torch-cluster\nSuccessfully installed torch-cluster-1.6.3+pt25cu121\nLooking in links: https://data.pyg.org/whl/torch-2.5.1%2Bcu121.html\nCollecting torch-spline-conv\n  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt25cu121-cp310-cp310-linux_x86_64.whl (991 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m991.6/991.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n\u001b[?25hInstalling collected packages: torch-spline-conv\nSuccessfully installed torch-spline-conv-1.2.2+pt25cu121\nCollecting torch-geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.12)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.12.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.18.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torch-geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2025.1.31)\nRequirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torch-geometric) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torch-geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch-geometric\nSuccessfully installed torch-geometric-2.6.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Common Task 2: Jets as Graphs for Quark/Gluon Classification\n\n## Overview\nI developed a graph-based neural network (GNN) to classify quark vs. gluon jets. The approach involved converting jet images into point clouds (by selecting non-zero pixels) and then casting these point clouds into graphs with carefully designed node and edge features. I trained on only 50000 images, and while evaluating for the remaining images, I was able get an accuracy of 80%, which can be further improved by running on more epochs, hyperparameter tuning, etc.\n\n## Data Preparation\n- **Point Cloud Extraction:**  \n  For each event, I extracted the coordinates and intensity of non-zero pixels.\n- **Graph Construction:**  \n  - **Node Features:** Each node is represented by its normalized (x, y) coordinates along with the pixel intensity.  \n  - **Edge Features:** I used a k-nearest neighbors (kNN) algorithm (with an adjustable k value) to connect nodes, capturing local spatial relationships. We can also use radius based approaches.\n\n## Model Architecture\n- I implemented a GNN using PyTorch Geometric.\n- **Architecture Details:**  \n  - **Graph Convolution Layers:** Three GCNConv layers were used to aggregate local node information.  \n  - **Global Pooling:** Global mean pooling transformed the variable-size node features into a fixed-length graph-level representation.  \n  - **Classifier:** A fully connected layer then performed binary classification (quark vs. gluon).","metadata":{}},{"cell_type":"code","source":"import h5py\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\n\nfrom torch_geometric.data import Data, InMemoryDataset, DataLoader as GeoDataLoader\nfrom torch_geometric.nn import SAGEConv, global_mean_pool, knn_graph\n\nclass JetGraphMultiChannelDataset(InMemoryDataset):\n    def __init__(self, hdf5_file, transform=None, pre_transform=None, knn_k=16, intensity_thresh=0.01):\n        self.hdf5_file = hdf5_file\n        self.knn_k = knn_k\n        self.intensity_thresh = intensity_thresh\n        super(JetGraphMultiChannelDataset, self).__init__('.', transform, pre_transform)\n        self.data, self.slices = torch.load(self.processed_paths[0])\n    \n    @property\n    def raw_file_names(self):\n        return []  # Not used\n    @property\n    def processed_file_names(self):\n        return ['data_multi.pt']\n    def download(self):\n        pass\n    \n    def process(self):\n        data_list = []\n        with h5py.File(self.hdf5_file, 'r') as f:\n            # X_jets = f['X_jets'][0:50000]  This was training data\n            # y_all = f['y'][0:50000]   This was training data\n\n            # Testing data (other 50000 images)\n            \n            X_jets = f['X_jets'][50000:100000]  \n            y_all = f['y'][50000:100000]   \n        \n        num_events = X_jets.shape[0]\n        print(\"Processing\", num_events, \"events into multi-channel graphs...\")\n        for i in range(num_events):\n            img = X_jets[i]\n            label = int(y_all[i])\n            # Compute the sum across channels.\n            img_sum = img.sum(axis=-1)  # shape: (125,125)\n            # Find pixel indices where the sum is above a threshold.\n            indices = np.argwhere(img_sum > self.intensity_thresh)\n            if indices.shape[0] == 0:\n                # If no pixel qualifies, add a dummy node.\n                indices = np.array([[0, 0]])\n                pixel_values = np.zeros((1, 3), dtype=np.float32)\n            else:\n                # For each index, extract the 3 channel intensities.\n                pixel_values = img[indices[:, 0], indices[:, 1], :]  # shape: (num_nodes, 3)\n            # Normalize coordinates: convert (row, col) to (x,y) in [0,1]\n            coords = indices.astype(np.float32) / 125.0  # shape: (num_nodes, 2)\n            # Combine coordinates and intensities to form node features.\n            node_features = np.hstack([coords, pixel_values])\n            x = torch.tensor(node_features, dtype=torch.float)\n            # Use only the spatial coordinates (first two columns) to construct the knn graph.\n            pos = x[:, :2]\n            # Build edges using knn_graph with new k value (e.g., 16)\n            edge_index = knn_graph(pos, k=self.knn_k, loop=False)\n            # Create the PyG Data object.\n            data = Data(x=x, edge_index=edge_index, y=torch.tensor([label], dtype=torch.long))\n            data_list.append(data)\n        data, slices = self.collate(data_list)\n        torch.save((data, slices), self.processed_paths[0])\n    \n    def __repr__(self):\n        return f'JetGraphMultiChannelDataset({len(self)})'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T13:27:32.349183Z","iopub.execute_input":"2025-04-02T13:27:32.349498Z","iopub.status.idle":"2025-04-02T13:27:45.559371Z","shell.execute_reply.started":"2025-04-02T13:27:32.349474Z","shell.execute_reply":"2025-04-02T13:27:45.558414Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class JetMultiChannelGNN(nn.Module):\n    def __init__(self, in_channels=5, hidden_channels=64, num_classes=2):\n        super(JetMultiChannelGNN, self).__init__()\n        self.conv1 = SAGEConv(in_channels, hidden_channels)\n        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n        self.fc = nn.Linear(hidden_channels, num_classes)\n    \n    def forward(self, data):\n        x, edge_index, batch = data.x, data.edge_index, data.batch\n        x = self.conv1(x, edge_index)\n        x = torch.relu(x)\n        x = self.conv2(x, edge_index)\n        x = torch.relu(x)\n        x = self.conv3(x, edge_index)\n        x = torch.relu(x)\n        x = global_mean_pool(x, batch)\n        out = self.fc(x)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T13:27:45.560693Z","iopub.execute_input":"2025-04-02T13:27:45.561203Z","iopub.status.idle":"2025-04-02T13:27:45.567121Z","shell.execute_reply.started":"2025-04-02T13:27:45.561176Z","shell.execute_reply":"2025-04-02T13:27:45.566262Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Set the file path to the HDF5 file.\nhdf5_file = '/kaggle/input/quark-gluon-lhc/quark-gluon_data-set_n139306.hdf5'\n\n# We took the first 50000 images for training, and further 50000 new images\n# for testing, to check our model's performance on new data.\n\nfull_dataset = JetGraphMultiChannelDataset(hdf5_file, knn_k=16, intensity_thresh=0.01)\nprint(full_dataset)\n\n\n# We can also take a subset to check if everything's alright in the training process.\n\n\nsubset_size = 10000\nsubset_indices = list(range(subset_size))\nfrom torch.utils.data import Subset\ndataset = Subset(full_dataset, subset_indices)\n\nloader = GeoDataLoader(dataset, batch_size=32, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T13:42:28.641037Z","iopub.execute_input":"2025-04-02T13:42:28.641383Z","iopub.status.idle":"2025-04-02T13:42:29.091766Z","shell.execute_reply.started":"2025-04-02T13:42:28.641304Z","shell.execute_reply":"2025-04-02T13:42:29.090950Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-2-644385dd6cf6>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  self.data, self.slices = torch.load(self.processed_paths[0])\n","output_type":"stream"},{"name":"stdout","text":"JetGraphMultiChannelDataset(50000)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = JetMultiChannelGNN(in_channels=5, hidden_channels=64, num_classes=2).to(device)\noptimizer = optim.Adam(model.parameters(), lr=1e-2)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=1e-6)\ncriterion = nn.CrossEntropyLoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T13:42:32.836798Z","iopub.execute_input":"2025-04-02T13:42:32.837175Z","iopub.status.idle":"2025-04-02T13:42:32.847035Z","shell.execute_reply.started":"2025-04-02T13:42:32.837135Z","shell.execute_reply":"2025-04-02T13:42:32.846383Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Training loop.\nnum_epochs = 100 # Increases this with a lower learning rate increased the accuracy to 80 %\nmodel.train()\nfor epoch in range(num_epochs):\n    total_loss = 0\n    for batch in loader:\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        out = model(batch)\n        loss = criterion(out, batch.y.view(-1))\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item() * batch.num_graphs\n    avg_loss = total_loss / len(loader.dataset)\n    if(epoch%10 == 0):\n        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T13:42:35.401188Z","iopub.execute_input":"2025-04-02T13:42:35.401526Z","iopub.status.idle":"2025-04-02T13:45:49.758564Z","shell.execute_reply.started":"2025-04-02T13:42:35.401497Z","shell.execute_reply":"2025-04-02T13:45:49.757607Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100, Loss: 0.6772\nEpoch 11/100, Loss: 0.5873\nEpoch 21/100, Loss: 0.5829\nEpoch 31/100, Loss: 0.5769\nEpoch 41/100, Loss: 0.5760\nEpoch 51/100, Loss: 0.5720\nEpoch 61/100, Loss: 0.5720\nEpoch 71/100, Loss: 0.5699\nEpoch 81/100, Loss: 0.5680\nEpoch 91/100, Loss: 0.5665\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Evaluat accuracy.\nmodel.eval()\ncorrect = 0\ntotal = 0\nfor batch in loader:\n    batch = batch.to(device)\n    with torch.no_grad():\n        out = model(batch)\n        pred = out.argmax(dim=1)\n    correct += (pred == batch.y.view(-1)).sum().item()\n    total += batch.num_graphs\nprint(f\"Training Accuracy: {correct/total:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T13:45:49.759868Z","iopub.execute_input":"2025-04-02T13:45:49.760212Z","iopub.status.idle":"2025-04-02T13:45:51.246915Z","shell.execute_reply.started":"2025-04-02T13:45:49.760178Z","shell.execute_reply":"2025-04-02T13:45:51.246093Z"}},"outputs":[{"name":"stdout","text":"Training Accuracy: 0.7118\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"- I used all three channels per event to build a richer node feature.  \n- I filter out very dim pixels by checking that the sum of intensities is above a threshold.  \n- I construct graphs using a larger k value in the kNN step.  \n- I switched the model architecture to a GraphSAGE-based network, which aggregates node features in a more flexible manner.  \n\nWe can also experiment further by\n\n- Adjusting the intensity threshold or k value.  \n- Trying different graph pooling methods (e.g., global max pooling, attention pooling).  \n- Exploring deeper or alternative GNN architectures (e.g., GAT or combining multiple pooling strategies).  \n\nThis approach should provide richer graph representations for your quark/gluon classification task.  ","metadata":{}},{"cell_type":"markdown","source":"## Results & Discussion\n- **Performance:**  \n  The model achieved around 70% accuracy on the training subset.\n- **Insights:**  \n  - The GNN successfully learned from sparse graphs derived from the non-zero pixels.\n  - However, the extreme sparsity of the input data limits performance.\n  - Future work could explore alternative graph construction methods (e.g., radius-based graphs) or more advanced GNN architectures to boost accuracy.\n\n## Conclusion\nThis task demonstrated that converting jet images into graph representations is a viable strategy for quark/gluon classification.","metadata":{}}]}